{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "!git clone https://github.com/bjoernssen/unet_simulation.git ./unet_sim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd unet_sim\n",
    "! git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 192, 192, 3)\n",
      "0 255\n",
      "(3, 6, 192, 192)\n",
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x864 with 6 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import simulation, helper\n",
    "input_images, target_masks = simulation.generate_random_data(192, 192, count=3)\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image, Right: Target mask\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "{'train': 20, 'val': 20}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from models.datasets import SimDataset\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(20, transform=trans)\n",
    "val_set = SimDataset(20, transform=trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           9,408\n",
      "            Conv2d-6         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-7         [-1, 64, 112, 112]             128\n",
      "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
      "              ReLU-9         [-1, 64, 112, 112]               0\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "        MaxPool2d-11           [-1, 64, 56, 56]               0\n",
      "        MaxPool2d-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-14           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-28           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
      "             ReLU-31           [-1, 64, 56, 56]               0\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-34           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-35           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-36           [-1, 64, 56, 56]             128\n",
      "             ReLU-37           [-1, 64, 56, 56]               0\n",
      "             ReLU-38           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-39           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-40           [-1, 64, 56, 56]               0\n",
      "           Conv2d-41          [-1, 128, 28, 28]          73,728\n",
      "           Conv2d-42          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "             ReLU-46          [-1, 128, 28, 28]               0\n",
      "           Conv2d-47          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-48          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "           Conv2d-51          [-1, 128, 28, 28]           8,192\n",
      "           Conv2d-52          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "             ReLU-56          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-57          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-60          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-61          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-62          [-1, 128, 28, 28]             256\n",
      "             ReLU-63          [-1, 128, 28, 28]               0\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-66          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-67          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "             ReLU-70          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-71          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-72          [-1, 128, 28, 28]               0\n",
      "           Conv2d-73          [-1, 256, 14, 14]         294,912\n",
      "           Conv2d-74          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-75          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "             ReLU-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-80          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-82          [-1, 256, 14, 14]             512\n",
      "           Conv2d-83          [-1, 256, 14, 14]          32,768\n",
      "           Conv2d-84          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-85          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-86          [-1, 256, 14, 14]             512\n",
      "             ReLU-87          [-1, 256, 14, 14]               0\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-89          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-90          [-1, 256, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-92          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-93          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-98          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-99          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "            ReLU-101          [-1, 256, 14, 14]               0\n",
      "            ReLU-102          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-103          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-104          [-1, 256, 14, 14]               0\n",
      "          Conv2d-105            [-1, 512, 7, 7]       1,179,648\n",
      "          Conv2d-106            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-108            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-109            [-1, 512, 7, 7]               0\n",
      "            ReLU-110            [-1, 512, 7, 7]               0\n",
      "          Conv2d-111            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-115            [-1, 512, 7, 7]         131,072\n",
      "          Conv2d-116            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-118            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-119            [-1, 512, 7, 7]               0\n",
      "            ReLU-120            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "          Conv2d-123            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-124            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-125            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-126            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-127            [-1, 512, 7, 7]               0\n",
      "            ReLU-128            [-1, 512, 7, 7]               0\n",
      "          Conv2d-129            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-130            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-131            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-132            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-133            [-1, 512, 7, 7]               0\n",
      "            ReLU-134            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-135            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-136            [-1, 512, 7, 7]               0\n",
      "          Conv2d-137            [-1, 512, 7, 7]         262,656\n",
      "            ReLU-138            [-1, 512, 7, 7]               0\n",
      "        Upsample-139          [-1, 512, 14, 14]               0\n",
      "          Conv2d-140          [-1, 256, 14, 14]          65,792\n",
      "            ReLU-141          [-1, 256, 14, 14]               0\n",
      "          Conv2d-142          [-1, 512, 14, 14]       3,539,456\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "        Upsample-144          [-1, 512, 28, 28]               0\n",
      "          Conv2d-145          [-1, 128, 28, 28]          16,512\n",
      "            ReLU-146          [-1, 128, 28, 28]               0\n",
      "          Conv2d-147          [-1, 256, 28, 28]       1,474,816\n",
      "            ReLU-148          [-1, 256, 28, 28]               0\n",
      "        Upsample-149          [-1, 256, 56, 56]               0\n",
      "          Conv2d-150           [-1, 64, 56, 56]           4,160\n",
      "            ReLU-151           [-1, 64, 56, 56]               0\n",
      "          Conv2d-152          [-1, 256, 56, 56]         737,536\n",
      "            ReLU-153          [-1, 256, 56, 56]               0\n",
      "        Upsample-154        [-1, 256, 112, 112]               0\n",
      "          Conv2d-155         [-1, 64, 112, 112]           4,160\n",
      "            ReLU-156         [-1, 64, 112, 112]               0\n",
      "          Conv2d-157        [-1, 128, 112, 112]         368,768\n",
      "            ReLU-158        [-1, 128, 112, 112]               0\n",
      "        Upsample-159        [-1, 128, 224, 224]               0\n",
      "          Conv2d-160         [-1, 64, 224, 224]         110,656\n",
      "            ReLU-161         [-1, 64, 224, 224]               0\n",
      "          Conv2d-162          [-1, 6, 224, 224]             390\n",
      "================================================================\n",
      "Total params: 28,976,646\n",
      "Trainable params: 28,976,646\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 417.65\n",
      "Params size (MB): 110.54\n",
      "Estimated Total Size (MB): 528.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "from models.nets import ResNetUNet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(n_class=6)\n",
    "base_model = model.to(device)\n",
    "\n",
    "summary(base_model, input_size=(3, 224, 224))\n",
    "torch.save(base_model, 'unet_sim.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.net_functions import convrelu\n",
    "from models.nets import ResNetUNet\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(6)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(3, 224, 224))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from utils.loss import dice_loss\n",
    "from utils.net_functions import calc_loss, print_metrics\n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 6\n",
    "\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "# Comment out to finetune further\n",
    "for l in model.base_layers:\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=15)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "\n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-4f50bddf",
   "language": "python",
   "display_name": "PyCharm (pytorch-unet-master)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}